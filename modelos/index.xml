<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modelos-rsses on Curso-R</title>
    <link>/modelos/index.xml</link>
    <description>Recent content in Modelos-rsses on Curso-R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <copyright>Disponível sobre Licença MIT</copyright>
    <lastBuildDate>Fri, 27 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/modelos/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Modelagem</title>
      <link>/modelos/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/modelos/</guid>
      <description>

&lt;h2 id=&#34;aprendizado-estatístico&#34;&gt;Aprendizado Estatístico&lt;/h2&gt;

&lt;p&gt;O termos &lt;em&gt;Aprendizado Estatístico&lt;/em&gt; refere-se a uma vasta quantidade de ferramentas
que são utilizadas para entender dados. Essas ferramentas são classificadas em
&lt;strong&gt;supervisionadas&lt;/strong&gt; e &lt;strong&gt;não-supervisionadas&lt;/strong&gt;. De forma geral, aprendizado
supervisionado envolve a construção de um modelo estatístico para prever ou estimar
uma &lt;strong&gt;resposta&lt;/strong&gt; de acordo com uma ou mais informações de entrada. No aprendizado
não-supervisionado existem variáveis de entrada mas não existe uma variável resposta.
Neste caso, o objetivo é entender a estrutura e a relação entre as variáveis. Existe
uma terceira classificação para as ferramentas de aprendizado estatístico chamada
&lt;a href=&#34;https://en.wikipedia.org/wiki/Reinforcement_learning&#34;&gt;Reinforcement Learning&lt;/a&gt;, mas
não abordaremos este tema neste material.&lt;/p&gt;

&lt;h3 id=&#34;exemplos&#34;&gt;Exemplos&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Um estudo estatístico cujo objetivo é estimar a probabilidade de uma transação
ser uma fraude e são fornecidos dados relativos a transações passadas bem como se
estas foram uma fraude ou não. É considerado um estudo de aprendizado supervisionado.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Um estudo em que são fornecidas diversas informações sobre os hábitos de compras
dos clientes e deseja-se identificar diferentes segmentos, é um
estudo de aprendizado não-supervisionado.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;Neste material vamos abordar incialmente algumas técnicas de aprendizado supervisionado.
Em seguida abordaremos abordaremos superficialmente alguns conceitos de aprendizado
não-supervisionado. Todos esses conceitos serão apresentados com exemplos práticos
usando o R.&lt;/p&gt;

&lt;p&gt;Para se aprofundar mais no assunto os seguintes links são ótimas referências.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf&#34;&gt;An Introduction to Statistical Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/practical-machine-learning&#34;&gt;Coursera - Practical Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;aprendizado-supervisionado&#34;&gt;Aprendizado Supervisionado&lt;/h2&gt;

&lt;p&gt;Suponha que você observou uma variável resposta $Y$ e $p$ diferentes variáveis
explicativas $X_1, X_2, &amp;hellip;, X_p$. Assumimos que existe alguma relação entre $Y$
e $X = (X_1, X_2, &amp;hellip;, X_p)$. Podemos denotar matematicamente esta relação como
na seguinte equação:&lt;/p&gt;

&lt;p&gt;$$Y = f(X) + \epsilon$$&lt;/p&gt;

&lt;p&gt;O objetivo geral do aprendizado supervisionado é estimar a função $f$.
Nessa formulação, $\epsilon$ é um termo de erro aleatório com média 0. $f$ representa
a informação sistemática que $X$ fornece sobre $Y$.&lt;/p&gt;

&lt;h3 id=&#34;modelos-lineares&#34;&gt;Modelos lineares&lt;/h3&gt;

&lt;p&gt;O modelo linear assume que a função $f$ é uma função linear de modo que a formulação
do apredizado supervisionado pode ser reescrita da seguinte forma:&lt;/p&gt;

&lt;p&gt;$$Y = \alpha + X\beta + \epsilon$$
Em que $\alpha$ e $\beta$ são coeficientes que serão estimados. Esses valores são
calculados de forma a minimizar uma &lt;strong&gt;função de perda&lt;/strong&gt; na sua amostra. A função
mais utilizada é a perda quadrática na sua amostra. Considere $(y_1, x_1)$, $(y_2, x_2)$, &amp;hellip;, $(y_n, x_n)$ uma amostra de tamanho $n$.&lt;/p&gt;

&lt;p&gt;$\alpha$ e $\beta$ são escolhidos de tal forma que:&lt;/p&gt;

&lt;p&gt;$$\sum_{i = 1}^{n} [y_i - (\alpha + \beta x_i)]^2$$
seja o menor possível. Isto é, estamos minimizando o &lt;em&gt;erro quadrático&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Na ótica da estatística, assumimos também que $Y \sim Normal(\alpha + X \beta, \sigma^2)$,
escolhemos $\alpha$ e $\beta$ de forma que maximize uma função que chamamos de &lt;a href=&#34;https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_de_verossimilhan%C3%A7a&#34;&gt;verossimilhança&lt;/a&gt;.
Essa suposição é útil quando queremos fazer testes de hipóteses e intervalos de
confiança. Por enquanto, não estamos interessados nisso e portanto vamos
apresentar uma visão menos complexa.&lt;/p&gt;

&lt;h4 id=&#34;exemplo&#34;&gt;Exemplo&lt;/h4&gt;

&lt;p&gt;Considere o banco de dados &lt;em&gt;BodyFat&lt;/em&gt; obtido &lt;a href=&#34;http://www2.stetson.edu/~jrasp/data.htm&#34;&gt;aqui&lt;/a&gt;.
Esses são dados do percentual de gordura corporal em uma amostra de 252 homens junto com
diversas outras medidas corporais. O percentual de gordura corporal é medido pesando
a pessoa sob a água, um procedimento trabalhoso. O objetivo é fazer um modelo linear
que permita obter o percentual de gordura usando medidas do corpo fáceis de serem obtidas.
Os dados são do site do Journal of Statistics Education.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(readxl)
library(dplyr)
library(ggplot2)
bodyfat &amp;lt;- read_excel(&#39;data/BodyFat.xls&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(bodyfat, aes(x = WEIGHT, y = BODYFAT)) + geom_point()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;figures//unnamed-chunk-7-1.png&#34; title=&#34;plot of chunk unnamed-chunk-7&#34; alt=&#34;plot of chunk unnamed-chunk-7&#34; width=&#34;50%&#34; height=&#34;50%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A partir do gráfico de dispersão, vemos que o peso do indivíduo parece ser &lt;strong&gt;linearmente&lt;/strong&gt;
relacionado ao percentual de gordura corporal. Vamos então ajustar um modelo linear
usando o R. Para ajustar o modelo, usamos a função &lt;code&gt;lm&lt;/code&gt; (de &lt;em&gt;&lt;strong&gt;l&lt;/strong&gt;inear &lt;strong&gt;m&lt;/strong&gt;odel&lt;/em&gt;).
A função &lt;code&gt;lm&lt;/code&gt;, assim como muitas outras que ajustam modelo no R, recebe como argumentos
uma formula e um banco de dados.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;formula&lt;/code&gt; é um tipo especial de objeto no R que ajuda muito na especificação dos modelos.
Ela tem a forma &lt;code&gt;y ~ x1 + x2 + ... + xn&lt;/code&gt; em que &lt;code&gt;y&lt;/code&gt; é o nome da variável resposta e &lt;code&gt;x1&lt;/code&gt;,
&lt;code&gt;x2&lt;/code&gt;, &amp;hellip;, &lt;code&gt;xn&lt;/code&gt; são os nomes das variáveis que serão utilizadas como explicativas.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ajuste &amp;lt;- lm(BODYFAT ~ WEIGHT, data = bodyfat)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Com essa chamada da função criamos o objeto &lt;code&gt;ajuste&lt;/code&gt;. Esse objeto abriga informações
relacionadas ao ajuste do modelo.&lt;/p&gt;

&lt;p&gt;$$bodyfat = \alpha + \beta*weight + \epsilon$$
As estimativas de $\alpha$ e $\beta$ podem ser encontradas usando a função &lt;code&gt;summary&lt;/code&gt;.
A estimativa de $\alpha$ é o valor da coluna &lt;code&gt;Estimate&lt;/code&gt; na linha &lt;code&gt;(Intercept)&lt;/code&gt;: -9.99515
e a estimativa de $\beta$ é o valor logo abaixo: 0.16171.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(ajuste)
## 
## Call:
## lm(formula = BODYFAT ~ WEIGHT, data = bodyfat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -16.434  -4.315   0.079   4.540  19.681 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -9.99515    2.38906  -4.184 3.97e-05 ***
## WEIGHT       0.16171    0.01318  12.273  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.135 on 250 degrees of freedom
## Multiple R-squared:  0.376,	Adjusted R-squared:  0.3735 
## F-statistic: 150.6 on 1 and 250 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Em R, o ajuste de um modelo estatístico é salvo em um objeto. Esse objeto é uma
&lt;code&gt;list&lt;/code&gt; que armazena diversas informações sobre o ajuste. Você pode ver algumas
informações disponíveis quando vê a estrutura do objeto &lt;code&gt;ajuste&lt;/code&gt; usando a função
&lt;code&gt;str&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(ajuste, max.level = 1)
## List of 12
##  $ coefficients : Named num [1:2] -9.995 0.162
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr [1:2] &amp;quot;(Intercept)&amp;quot; &amp;quot;WEIGHT&amp;quot;
##  $ residuals    : Named num [1:252] -2.35 -11.12 9.69 -8.98 8 ...
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr [1:252] &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;4&amp;quot; ...
##  $ effects      : Named num [1:252] -300.64 75.29 10.38 -9.01 7.98 ...
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr [1:252] &amp;quot;(Intercept)&amp;quot; &amp;quot;WEIGHT&amp;quot; &amp;quot;&amp;quot; &amp;quot;&amp;quot; ...
##  $ rank         : int 2
##  $ fitted.values: Named num [1:252] 14.9 18 14.9 19.9 19.8 ...
##   ..- attr(*, &amp;quot;names&amp;quot;)= chr [1:252] &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;4&amp;quot; ...
##  $ assign       : int [1:2] 0 1
##  $ qr           :List of 5
##   ..- attr(*, &amp;quot;class&amp;quot;)= chr &amp;quot;qr&amp;quot;
##  $ df.residual  : int 250
##  $ xlevels      : Named list()
##  $ call         : language lm(formula = BODYFAT ~ WEIGHT, data = bodyfat)
##  $ terms        :Classes &#39;terms&#39;, &#39;formula&#39;  language BODYFAT ~ WEIGHT
##   .. ..- attr(*, &amp;quot;variables&amp;quot;)= language list(BODYFAT, WEIGHT)
##   .. ..- attr(*, &amp;quot;factors&amp;quot;)= int [1:2, 1] 0 1
##   .. .. ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..- attr(*, &amp;quot;term.labels&amp;quot;)= chr &amp;quot;WEIGHT&amp;quot;
##   .. ..- attr(*, &amp;quot;order&amp;quot;)= int 1
##   .. ..- attr(*, &amp;quot;intercept&amp;quot;)= int 1
##   .. ..- attr(*, &amp;quot;response&amp;quot;)= int 1
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x15a8688&amp;gt; 
##   .. ..- attr(*, &amp;quot;predvars&amp;quot;)= language list(BODYFAT, WEIGHT)
##   .. ..- attr(*, &amp;quot;dataClasses&amp;quot;)= Named chr [1:2] &amp;quot;numeric&amp;quot; &amp;quot;numeric&amp;quot;
##   .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr [1:2] &amp;quot;BODYFAT&amp;quot; &amp;quot;WEIGHT&amp;quot;
##  $ model        :&#39;data.frame&#39;:	252 obs. of  2 variables:
##   ..- attr(*, &amp;quot;terms&amp;quot;)=Classes &#39;terms&#39;, &#39;formula&#39;  language BODYFAT ~ WEIGHT
##   .. .. ..- attr(*, &amp;quot;variables&amp;quot;)= language list(BODYFAT, WEIGHT)
##   .. .. ..- attr(*, &amp;quot;factors&amp;quot;)= int [1:2, 1] 0 1
##   .. .. .. ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. .. ..- attr(*, &amp;quot;term.labels&amp;quot;)= chr &amp;quot;WEIGHT&amp;quot;
##   .. .. ..- attr(*, &amp;quot;order&amp;quot;)= int 1
##   .. .. ..- attr(*, &amp;quot;intercept&amp;quot;)= int 1
##   .. .. ..- attr(*, &amp;quot;response&amp;quot;)= int 1
##   .. .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x15a8688&amp;gt; 
##   .. .. ..- attr(*, &amp;quot;predvars&amp;quot;)= language list(BODYFAT, WEIGHT)
##   .. .. ..- attr(*, &amp;quot;dataClasses&amp;quot;)= Named chr [1:2] &amp;quot;numeric&amp;quot; &amp;quot;numeric&amp;quot;
##   .. .. .. ..- attr(*, &amp;quot;names&amp;quot;)= chr [1:2] &amp;quot;BODYFAT&amp;quot; &amp;quot;WEIGHT&amp;quot;
##  - attr(*, &amp;quot;class&amp;quot;)= chr &amp;quot;lm&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Por exemplo você pode acessar os coeficientes do modelo usando &lt;code&gt;ajuste$coefficients&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Outra função que existe para a maior parte dos modelos que podem ser ajustados usando o R
a &lt;code&gt;predict&lt;/code&gt;. Usamos a função &lt;code&gt;predict&lt;/code&gt; para obter as estimativas do modelo ajustado para
uma base de dados (nova ou não).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;bodyfat$predito_modelo1 &amp;lt;- predict(ajuste, newdata = bodyfat)
bodyfat %&amp;gt;% select(WEIGHT, BODYFAT, predito_modelo1) %&amp;gt;% head() %&amp;gt;% knitr::kable()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;WEIGHT&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;BODYFAT&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;predito_modelo1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;154.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14.94842&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;173.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.02089&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;154.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14.90800&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;184.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.88054&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;184.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27.8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.79969&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;210.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.00412&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Nessa tabela, vemos o valor predito pelo modelo para cada observação bem como o
valor verdadeiro de gordura corporal daquele indivíduo. Nosso modelo não parece
estar muito bom. Uma possível medida de erro é o MSE (Erro quadrático médio).
Podemos calculá-lo fazendo contas simples no R.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mse &amp;lt;- mean((bodyfat$BODYFAT - bodyfat$predito_modelo1)^2)
mse
## [1] 37.34089
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;É mais fácil identificar se esse erro é baixo ou não comparando-o com o erro se
usássemos a média da variável como valor predito para todas as observações e
tirando a raíz quadrada dos dois.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;erro_usando_media &amp;lt;- mean((bodyfat$BODYFAT - mean(bodyfat$BODYFAT))^2)
erro_usando_media
## [1] 59.83737

sqrt(mse)
## [1] 6.110719
sqrt(erro_usando_media)
## [1] 7.735462
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora podemos ter uma ideia de que o nosso erro está alto. Se usássemos apenas a
média erraríamos em média 7,7 usando o nosso modelo, ficamos com 6,1.&lt;/p&gt;

&lt;p&gt;Felizmente, podemos melhorar o modelo adicionando mais variáveis. No R basta:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ajuste2 &amp;lt;- lm(BODYFAT ~ WEIGHT + HEIGHT + CHEST + ABDOMEN + NECK + KNEE, 
              data = bodyfat)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O erro pode ser novamente calculado repetindo as operações que fizemos anteriormente.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;bodyfat$predito_modelo2 &amp;lt;- predict(ajuste2, newdata = bodyfat)
mse &amp;lt;- mean((bodyfat$BODYFAT - bodyfat$predito_modelo2)^2)
sqrt(mse)
## [1] 4.049453
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora reduzimos bastante o erro. É muito importante ressaltar que estamos avaliando
o erro dentro da mesma base de dados que utilizamos para ajustar o modelo. Isso é
considerado uma má prática, pois podemos facilmente esbarrar em uma situação de
&lt;em&gt;superajuste&lt;/em&gt; ou &lt;em&gt;overfitting&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Até agora vimos que usando a função &lt;code&gt;lm&lt;/code&gt; podemos ajustar um modelo linear usando o
R. Esse único comando, que recebe um formula e um banco de dados, retorna um objeto
que é similar a uma &lt;code&gt;list&lt;/code&gt; e que armazena uma variedade de informações sobre o
ajuste como coeficientes, dados utilizados, etc. Aprendemos também a função &lt;code&gt;summary&lt;/code&gt;,
que &amp;ldquo;imprime&amp;rdquo; no console uma série de informações sobre o ajuste. Também vimos a
função &lt;code&gt;predict&lt;/code&gt; que é utilizada pra obter os valores preditos pelo modelo para
uma nova base de dados.&lt;/p&gt;

&lt;p&gt;Mais tarde falaremos novamente sobre modelos lineares quando falarmos sobre
&lt;a href=&#34;https://pt.wikipedia.org/wiki/Regress%C3%A3o_log%C3%ADstica&#34;&gt;regressão logística&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;árvore-de-decisão&#34;&gt;Árvore  de Decisão&lt;/h3&gt;

&lt;p&gt;Os modelos de árvore de decisão como vamos utilizar são implementados de acordo
com o livro &lt;em&gt;Classification and Regression Trees&lt;/em&gt; de Breiman, Friedman, Olshen e Stone.
No R, o pacote que usamos para fazer este tipo de análise é o &lt;code&gt;rpart&lt;/code&gt;. Uma
curiosidade é que gostariam que os autores do pacote gostariam de usar o nome &lt;code&gt;cart&lt;/code&gt;,
mas esse nome foi utilizado por uma implementação particular dessas ideias. No fim,
ficou mais famoso o &lt;code&gt;rpart&lt;/code&gt;, mostrando a importância do software livre.&lt;/p&gt;

&lt;p&gt;Não vamos entrar matematicamente no detalhe de como funciona uma árvore de decisão.
Para entender como funciona um árvore de decisão, imagine que você tem um nó com
$N$ observações e que $n$ possuem $Resposta = 1$ e $N - n$ possuem $Resposta = 0$,
ou seja, temos um problema de classificação binária. Então neste caso $p = \frac{n}{N}$
é a proporção de resposta neste nó.&lt;/p&gt;

&lt;p&gt;O objetivo da árvore de decisão dividir este nó em 2 de forma que a diferença entre
a proporção de respostas entre os dois nós resultantes seja a maior possível. Claro que
cada um dos nós precisa ter uma quantidade significativa de observações de forma que $p$
seja estimado corretamente.&lt;/p&gt;

&lt;p&gt;Uma introdução mais formal a esses métodos pode ser encontrada na vignette do pacote
&lt;code&gt;rpart&lt;/code&gt;. Digite &lt;code&gt;vignette(&#39;longintro&#39;, package = &#39;rpart&#39;)&lt;/code&gt; no console para encontrá-la.&lt;/p&gt;

&lt;h3 id=&#34;exemplo-1&#34;&gt;Exemplo&lt;/h3&gt;

&lt;p&gt;Para esse exemplo vamos usar o banco de dados do Titanic. Um banco de dados que
ficou famoso por causa de uma competição no Kaggle. Esse banco de dados contém
diversas informações sobre os passageiros do Titanic bem como uma variável que
indica se o passageiro sobreviveu (1) e se não sobreviveu (0).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(readr)
titanic &amp;lt;- read_csv(&#39;data/titanic-train.csv&#39;)
## Parsed with column specification:
## cols(
##   PassengerId = col_integer(),
##   Survived = col_integer(),
##   Pclass = col_integer(),
##   Name = col_character(),
##   Sex = col_character(),
##   Age = col_double(),
##   SibSp = col_integer(),
##   Parch = col_integer(),
##   Ticket = col_character(),
##   Fare = col_double(),
##   Cabin = col_character(),
##   Embarked = col_character()
## )
titanic$Survived &amp;lt;- as.factor(titanic$Survived)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Usando o &lt;code&gt;rpart&lt;/code&gt; podemos ajustar o modelo de árvore de cdecisão fazendo.
A função &lt;code&gt;rpart&lt;/code&gt; recebe uma fórmula indicando a variável resposta e as
variáveis que serão utilizadas no modelo, além de receber um argumento
&lt;code&gt;data&lt;/code&gt; que indica o banco de dados utilizado.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rpart)
arvore &amp;lt;- rpart(Survived ~ Sex + Age + Pclass, data = titanic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assim como na regressão linear, podemos ver informações sobre o ajuste
usando a função &lt;code&gt;summary&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(arvore)
## Call:
## rpart(formula = Survived ~ Sex + Age + Pclass, data = titanic)
##   n= 891 
## 
##           CP nsplit rel error    xerror       xstd
## 1 0.44444444      0 1.0000000 1.0000000 0.04244576
## 2 0.02339181      1 0.5555556 0.5555556 0.03574957
## 3 0.01461988      2 0.5321637 0.5760234 0.03621995
## 4 0.01169591      4 0.5029240 0.5614035 0.03588593
## 5 0.01000000      6 0.4795322 0.5263158 0.03504339
## 
## Variable importance
##    Sex Pclass    Age 
##     70     18     12 
## 
## Node number 1: 891 observations,    complexity param=0.4444444
##   predicted class=0  expected loss=0.3838384  P(node) =1
##     class counts:   549   342
##    probabilities: 0.616 0.384 
##   left son=2 (577 obs) right son=3 (314 obs)
##   Primary splits:
##       Sex    splits as  RL,       improve=124.426300, (0 missing)
##       Pclass &amp;lt; 2.5  to the right, improve= 43.781830, (0 missing)
##       Age    &amp;lt; 6.5  to the right, improve=  8.814172, (177 missing)
## 
## Node number 2: 577 observations,    complexity param=0.02339181
##   predicted class=0  expected loss=0.1889081  P(node) =0.647587
##     class counts:   468   109
##    probabilities: 0.811 0.189 
##   left son=4 (553 obs) right son=5 (24 obs)
##   Primary splits:
##       Age    &amp;lt; 6.5  to the right, improve=10.78893, (124 missing)
##       Pclass &amp;lt; 1.5  to the right, improve=10.01914, (0 missing)
## 
## Node number 3: 314 observations,    complexity param=0.01461988
##   predicted class=1  expected loss=0.2579618  P(node) =0.352413
##     class counts:    81   233
##    probabilities: 0.258 0.742 
##   left son=6 (144 obs) right son=7 (170 obs)
##   Primary splits:
##       Pclass &amp;lt; 2.5  to the right, improve=31.163130, (0 missing)
##       Age    &amp;lt; 12   to the left,  improve= 1.891684, (53 missing)
##   Surrogate splits:
##       Age &amp;lt; 18.5 to the left,  agree=0.564, adj=0.049, (0 split)
## 
## Node number 4: 553 observations
##   predicted class=0  expected loss=0.1681736  P(node) =0.620651
##     class counts:   460    93
##    probabilities: 0.832 0.168 
## 
## Node number 5: 24 observations
##   predicted class=1  expected loss=0.3333333  P(node) =0.02693603
##     class counts:     8    16
##    probabilities: 0.333 0.667 
## 
## Node number 6: 144 observations,    complexity param=0.01461988
##   predicted class=0  expected loss=0.5  P(node) =0.1616162
##     class counts:    72    72
##    probabilities: 0.500 0.500 
##   left son=12 (12 obs) right son=13 (132 obs)
##   Primary splits:
##       Age &amp;lt; 38.5 to the right, improve=3.875163, (42 missing)
## 
## Node number 7: 170 observations
##   predicted class=1  expected loss=0.05294118  P(node) =0.1907969
##     class counts:     9   161
##    probabilities: 0.053 0.947 
## 
## Node number 12: 12 observations
##   predicted class=0  expected loss=0.08333333  P(node) =0.01346801
##     class counts:    11     1
##    probabilities: 0.917 0.083 
## 
## Node number 13: 132 observations,    complexity param=0.01169591
##   predicted class=1  expected loss=0.4621212  P(node) =0.1481481
##     class counts:    61    71
##    probabilities: 0.462 0.538 
##   left son=26 (117 obs) right son=27 (15 obs)
##   Primary splits:
##       Age &amp;lt; 5.5  to the right, improve=1.777778, (42 missing)
## 
## Node number 26: 117 observations,    complexity param=0.01169591
##   predicted class=1  expected loss=0.4871795  P(node) =0.1313131
##     class counts:    57    60
##    probabilities: 0.487 0.513 
##   left son=52 (8 obs) right son=53 (109 obs)
##   Primary splits:
##       Age &amp;lt; 12   to the left,  improve=3.900498, (42 missing)
## 
## Node number 27: 15 observations
##   predicted class=1  expected loss=0.2666667  P(node) =0.01683502
##     class counts:     4    11
##    probabilities: 0.267 0.733 
## 
## Node number 52: 8 observations
##   predicted class=0  expected loss=0  P(node) =0.008978676
##     class counts:     8     0
##    probabilities: 1.000 0.000 
## 
## Node number 53: 109 observations
##   predicted class=1  expected loss=0.4495413  P(node) =0.1223345
##     class counts:    49    60
##    probabilities: 0.450 0.550
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Visualizar a árvore de decisão sempre dá bons &lt;em&gt;insights&lt;/em&gt;. Um pacote que é interessante
para visualizar a árvore de decisão construída com o &lt;code&gt;rpart&lt;/code&gt; é o &lt;code&gt;rpart.plot&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rpart.plot)
rpart.plot(arvore)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;figures//unnamed-chunk-19-1.png&#34; title=&#34;plot of chunk unnamed-chunk-19&#34; alt=&#34;plot of chunk unnamed-chunk-19&#34; width=&#34;70%&#34; height=&#34;70%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A visualização é bem intuitiva. No topo, vemos o primeiro nó em que 38% dos indivíduos
sobreviveram e que representa o total da base (100%). Em seguida, vemos que a primeira
variável que discrimina quem sobreviveu ou não é a variável Sexo: Dos homens, que eram 65%
dos passageiros, apenas 19% sobreviveu enquanto das mulheres, que eram 35%, 74% sobreviveu.
Dos homens, aqueles que eram menores de 6 anos e meio, sobreviveram em maior proporção
também. A interpretação pode continuar dessa forma recursivamente.&lt;/p&gt;

&lt;p&gt;Mais uma vez, assim como na regressão linear, podemos utilizar a função &lt;code&gt;predict&lt;/code&gt; para
obter a probabilidade predita de sobrevivência e a classificação predita para cada
observação. A diferença é que agora temos o parâmetros &lt;code&gt;type&lt;/code&gt;, que vai indicar se queremos
a probabilidade ou a classe predita.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;probabilidades &amp;lt;- predict(arvore, newdata = titanic, type = &#39;prob&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Com &lt;code&gt;type = &#39;prob&#39;&lt;/code&gt; obtemos uma &lt;code&gt;matrix&lt;/code&gt; em que cada coluna representa a probabilidade
predita para cada classe. Quando temos apenas um classe isso pode parecer desnecessário
já que o valor de uma coluna é a diferença de 1 pelo valor da outra, mas árvores podem
ser utilizadas em modelos com mais de classificação para mais de duas categorias.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;classes &amp;lt;- predict(arvore, newdata = titanic, type = &#39;class&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Quando você prevê a classe diretamente, o &lt;code&gt;rpart&lt;/code&gt; indica como predito quando a
probabilidade de sobrevivência é maior do que 50%. Isso nem sempre é o que garante
o maior ganho com o modelo. Principalmente em problemas em que as classes são muito
desbalanceadas. Além disso, em outros problemas, os custos de classificar uma observação
como positiva quando ela é negativa, podem ser diferentes de classificá-la como negativa
quando ela é positiva.&lt;/p&gt;

&lt;p&gt;Para escolher o melhor ponto de corte da probabilidade, podemos usar a curva ROC, e
uma função de custo. Existem diversos pacotes que ajudam a calcular essas medidas. Vamos fazer aqui sem usá-los para praticar.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
## Loading tidyverse: tibble
## Loading tidyverse: tidyr
## Loading tidyverse: purrr
## Conflicts with tidy packages ----------------------------------------------
## filter(): dplyr, stats
## lag():    dplyr, stats
cortes &amp;lt;- seq(0,1,by = 0.01)
valores &amp;lt;- map_df(cortes, function(x){
  tabela &amp;lt;- table(
    titanic$Survived, 
    factor(probabilidades[,2] &amp;gt; x, levels = c(&amp;quot;FALSE&amp;quot;, &amp;quot;TRUE&amp;quot;))
    )
  data_frame(
    corte = x,
    FPR = tabela[1,2]/sum(tabela[1,]),
    TPR = tabela[2,2]/sum(tabela[2,]),
    TNR = tabela[1,1]/sum(tabela[1,]),
    FNR = tabela[2,1]/sum(tabela[2,])
  )
})


ggplot(valores, aes(x = FPR, y = TPR)) + 
  geom_step() + 
  geom_abline(color = &#39;blue&#39;, linetype = &#39;dashed&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;figures//unnamed-chunk-22-1.png&#34; title=&#34;plot of chunk unnamed-chunk-22&#34; alt=&#34;plot of chunk unnamed-chunk-22&#34; width=&#34;50%&#34; height=&#34;50%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A função de custo pode ser calculada da seguinte forma. Veja que estamos considerando
pesos iguais para ambos os erros.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;valores %&amp;gt;%
  mutate(custo = FPR + FNR) %&amp;gt;%
  ggplot(aes(x = corte, y = custo)) +
  geom_line()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;figures//unnamed-chunk-23-1.png&#34; title=&#34;plot of chunk unnamed-chunk-23&#34; alt=&#34;plot of chunk unnamed-chunk-23&#34; width=&#34;50%&#34; height=&#34;50%&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Neste caso, o ponto mínimo da função é obtido com qualquer corte entre um pouco menos de 25%
até um pouco mais de 50%. Isso nem sempre é verdade e deve ser avaliado em cada modelo.&lt;/p&gt;

&lt;script src=&#34;https://cdn.datacamp.com/datacamp-light-latest.min.js&#34;&gt;&lt;/script&gt;

&lt;script src=&#34;https://cdn.datacamp.com/datacamp-light-latest.min.js&#34;&gt;&lt;/script&gt;

&lt;ol&gt;
&lt;li&gt;Calcule o número de ouro no R.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$$
\frac{1 + \sqrt{5}}{2}
$$&lt;/p&gt;

&lt;div data-datacamp-exercise data-height=&#34;300&#34; data-encoded=&#34;true&#34;&gt;eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERpZ2l0ZSBhIGV4cHJlc3NcdTAwZTNvIHF1ZSBjYWxjdWxhIG8gblx1MDBmYW1lcm8gZGUgb3Vyby4iLCJzb2x1dGlvbiI6IigxICsgc3FydCg1KSkvMiIsInNjdCI6InRlc3Rfb3V0cHV0X2NvbnRhaW5zKFwiMS42MTgwMzRcIiwgaW5jb3JyZWN0X21zZyA9IFwiVGVtIGNlcnRlemEgZGUgcXVlIGluZGljb3UgYSBleHByZXNzXHUwMGUzbyBjb3JyZXRhbWVudGU/XCIpXG5zdWNjZXNzX21zZyhcIkNvcnJldG8hXCIpIn0=&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
